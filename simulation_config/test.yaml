#Parallel Simulation(multiple backends):
#Prepare different configuration files in the following way.
#You can only specify the values which are changed compared with the default configuration.   

DDPG_Agent:
  #For ActorNet and CriticNet, any structure of fully connected layers is supported.
  #hidden_layers is written as yaml-style array, you can add more layers by expanding the first dim. of the array.
  #the seconde dim. of the array specifies the number of neurons in this layer and the corresponding activation function.   
  ActorNet:
    hidden_layers:
      -
        - 128
        - relu
      -
        - 128
        - relu
      -
        - 128
        - relu
    output_activation: sigmoid

  CriticNet:
    hidden_layers:
      -
        - 512
        - relu
      -
        - 256
        - relu
      -
        - 128
        - relu 
    output_activation: linear

  random_process: OrnsteinUhlenbeckProcess(theta=.15, mu=0., sigma=.2, size=nA) #size=nA should not be changed

  memory: SequentialMemory(limit=100000, window_length=1)

  agent:
    #keyword arguments for rl.agents.DDPGAgent()
    nb_steps_warmup_critic: 10
    nb_steps_warmup_actor: 10
    gamma: .99
    batch_size: 5
    target_model_update: 0.001
    delta_clip: 1.

  optimizer:
    Adam(lr=.001, clipnorm=1.)
  compiler:
    #keyword arguments for compile()
    metrics: 
      - mae

  weights_sav_path:
    /home/.opt/nrpStorage/template_new_1/ddpg_weights.h5

Environment:
  reward_function:
    5*link_vlin[0].x-link_vlin[0].y-2*link_vlin[0].z-1

Training_Script:
  Max_Epoch: 1000
